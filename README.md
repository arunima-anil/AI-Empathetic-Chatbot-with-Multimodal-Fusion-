# AI-Empathetic-Chatbot-with-Multimodal-Fusion

Welcome to the **AI Empathetic Chatbot with Multimodal Fusion** project! This innovative application combines emotion recognition from speech, text, and facial expressions to provide a personalized and empathetic conversational experience. The chatbot integrates various modalities to deliver contextually relevant responses, enhancing user interaction through emotional intelligence.

---

## Table of Contents

- [Features](#features)
- [Directory Structure](#directory-structure)
- [Technologies Used](#technologies-used)
- [Installation](#installation)
- [Usage](#usage)
- [Examples](#examples)
- [Contributing](#contributing)
- [License](#license)
- [Contact Information](#contact-information)
- [Acknowledgments](#acknowledgments)

---

## Features

- **Speech Emotion Recognition (SER):** Detects emotions from spoken words using advanced audio processing techniques.
- **Text Emotion Recognition (TER):** Analyzes and interprets emotions conveyed through text input.
- **Facial Emotion Recognition (FER):** Utilizes camera input to detect and interpret facial expressions.
- **BlenderBot Response:** Generates contextually relevant and empathetic responses based on detected emotions and user input.

---

## Directory Structure

```plaintext
AI-Empathetic-Chatbot-with-Multimodal-Fusion/
│
├── APP/
│   ├── CT_App.py             # Main application script
│   ├── CT_functions.py       # Supporting functions for the application
│   └── api.py                # API configuration and interactions
│
├── App Results/              # Results and screenshots of the application
│   └── Screenshot 2024-04-09 095017.png
│
├── Model Building/
│   ├── Results/              # Model building results
│   │   ├── download (3).png
│   │   └── download.png
│   └── [Model Files]         # Model files and configurations
│
├── README.md                 # Project documentation (this file)
├── requirements.txt          # Required libraries and dependencies
└── [Other Files and Directories]
